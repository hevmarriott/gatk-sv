version 1.0

import "CollectCoverage.wdl" as cov
import "GATKSVGenotype.wdl" as svg
import "GermlineCNVTasks.wdl" as gcnv_tasks

workflow GATKSVJoinSamples {
  input {
    Array[File] vcfs
    String batch
    Array[String] samples
    Array[File] counts
    Array[File] cnmops_files
    Array[File] large_gcnv_interval_vcfs

    File sr_file
    File pe_file
    File sample_coverage_file
    File gatk_sv_cluster_exclude_intervals
    File exclude_intervals
    File contig_list
    File ploidy_calls_tar

    Int min_depth_only_size = 5000
    Int? small_cnv_size
    Int? small_cnv_padding

    # Condense read counts
    Int condense_num_bins = 2
    Int condense_bin_size = 200

    File ref_fasta_dict
    File ref_fasta_fai
    File ref_fasta
    String linux_docker
    String sv_base_mini_docker
    String sv_pipeline_docker
    String sv_pipeline_base_docker
    String gcnv_gatk_docker
    String gatk_docker
    String condense_counts_docker

    RuntimeAttr? runtime_attr_merge
    RuntimeAttr? runtime_attr_filter_depth
    RuntimeAttr? runtime_attr_concat
    RuntimeAttr? runtime_attr_small_intervals
    RuntimeAttr? runtime_attr_intersect_intervals
    RuntimeAttr? runtime_attr_counts_to_intervals
    RuntimeAttr? runtime_attr_cluster
    RuntimeAttr? runtime_attr_posteriors
    RuntimeAttr? runtime_attr_merge_vcfs
    RuntimeAttr? runtime_attr_condense_counts

    RuntimeAttr? runtime_attr_annotate
    RuntimeAttr? runtime_attr_filter
    RuntimeAttr? runtime_attr_scatter
    RuntimeAttr? runtime_attr_ploidy
    RuntimeAttr? runtime_attr_cohort
    RuntimeAttr? runtime_attr_bundle
    RuntimeAttr? runtime_attr_postprocess
    RuntimeAttr? runtime_attr_explode

    ##################################
    #### required gcnv arguments ####
    ##################################
    File contig_ploidy_priors
    Int num_intervals_per_scatter

    ##################################
    #### optional basic arguments ####
    ##################################
    # If true, AnnotateIntervals will be run to create GC annotations and explicit
    # GC correction will be performed by the model generated by
    Boolean? do_explicit_gc_correction
    File? gatk4_jar_override

    ##################################################
    #### optional arguments for AnnotateIntervals ####
    ##################################################
    File? mappability_track_bed
    File? mappability_track_bed_idx
    File? segmental_duplication_track_bed
    File? segmental_duplication_track_bed_idx
    Int? feature_query_lookahead

    #################################################
    #### optional arguments for FilterIntervals ####
    ################################################
    Boolean? filter_intervals
    File? exclude_intervals_for_filter_intervals_ploidy
    File? exclude_intervals_for_filter_intervals_cnv
    Float? minimum_gc_content
    Float? maximum_gc_content
    Float? minimum_mappability
    Float? maximum_mappability
    Float? minimum_segmental_duplication_content
    Float? maximum_segmental_duplication_content
    Int? low_count_filter_count_threshold
    Float? low_count_filter_percentage_of_samples
    Float? extreme_count_filter_minimum_percentile
    Float? extreme_count_filter_maximum_percentile
    Float? extreme_count_filter_percentage_of_samples

    ########################################################################
    #### optional arguments for DetermineGermlineContigPloidyCohortMode ####
    ########################################################################
    Float? ploidy_mean_bias_standard_deviation
    Float? ploidy_mapping_error_rate
    Float? ploidy_global_psi_scale
    Float? ploidy_sample_psi_scale

    ############################################################
    #### optional arguments for GermlineCNVCallerCohortMode ####
    ############################################################
    Float? gcnv_p_alt
    Float? gcnv_p_active
    Float? gcnv_cnv_coherence_length
    Float? gcnv_class_coherence_length
    Int? gcnv_max_copy_number

    # optional arguments for germline CNV denoising model
    Int? gcnv_max_bias_factors
    Float? gcnv_mapping_error_rate
    Float? gcnv_interval_psi_scale
    Float? gcnv_sample_psi_scale
    Float? gcnv_depth_correction_tau
    Float? gcnv_log_mean_bias_standard_deviation
    Float? gcnv_init_ard_rel_unexplained_variance
    Int? gcnv_num_gc_bins
    Float? gcnv_gc_curve_standard_deviation
    String? gcnv_copy_number_posterior_expectation_mode
    Boolean? gcnv_enable_bias_factors
    Int? gcnv_active_class_padding_hybrid_mode

    # optional arguments for Hybrid ADVI
    Float? gcnv_learning_rate
    Float? gcnv_adamax_beta_1
    Float? gcnv_adamax_beta_2
    Int? gcnv_log_emission_samples_per_round
    Float? gcnv_log_emission_sampling_median_rel_error
    Int? gcnv_log_emission_sampling_rounds
    Int? gcnv_max_advi_iter_first_epoch
    Int? gcnv_max_advi_iter_subsequent_epochs
    Int? gcnv_min_training_epochs
    Int? gcnv_max_training_epochs
    Float? gcnv_initial_temperature
    Int? gcnv_num_thermal_advi_iters
    Int? gcnv_convergence_snr_averaging_window
    Float? gcnv_convergence_snr_trigger_threshold
    Int? gcnv_convergence_snr_countdown_window
    Int? gcnv_max_calling_iters
    Float? gcnv_caller_update_convergence_threshold
    Float? gcnv_caller_internal_admixing_rate
    Float? gcnv_caller_external_admixing_rate
    Boolean? gcnv_disable_annealing

    ###################################################
    #### arguments for PostprocessGermlineCNVCalls ####
    ###################################################
    Int ref_copy_number_autosomal_contigs
    Array[String]? allosomal_contigs
  }

  scatter (i in range(length(vcfs))) {
    File vcf_indexes_ = vcfs[i] + ".tbi"
  }

  scatter (i in range(length(cnmops_files))) {
    File cnmops_file_indexes_ = cnmops_files[i] + ".tbi"
  }

  scatter (i in range(length(large_gcnv_interval_vcfs))) {
    File large_gcnv_interval_vcf_indexes_ = large_gcnv_interval_vcfs[i] + ".tbi"
  }

  File sr_index_ = sr_file + ".tbi"
  File pe_index_ = pe_file + ".tbi"
  File exclude_intervals_index_ = exclude_intervals + ".tbi"

  call MergeSVCalls {
    input:
      vcfs = vcfs,
      vcf_indexes = vcf_indexes_,
      cnmops_files = cnmops_files,
      cnmops_file_indexes = cnmops_file_indexes_,
      batch = batch,
      ref_fasta_dict = ref_fasta_dict,
      gatk_docker = gatk_docker,
      runtime_attr_override = runtime_attr_merge
  }

  Array[String] contigs = read_lines(contig_list)

  scatter (contig in contigs) {
    call ClusterVariants {
      input:
        vcf = MergeSVCalls.out,
        vcf_index = MergeSVCalls.out_index,
        vid_prefix = "SV_" + contig + "_",
        contig = contig,
        sr_file = sr_file,
        sr_index = sr_index_,
        pe_file = pe_file,
        pe_index = pe_index_,
        sample_coverage_file = sample_coverage_file,
        gatk_sv_cluster_exclude_intervals = gatk_sv_cluster_exclude_intervals,
        exclude_intervals = exclude_intervals,
        exclude_intervals_index = exclude_intervals_index_,
        ref_fasta_dict = ref_fasta_dict,
        batch = batch + "." + contig,
        gatk_docker = gatk_docker,
        runtime_attr_override = runtime_attr_cluster
    }
  }

  call svg.ConcatVcfs {
    input:
      vcfs = ClusterVariants.out,
      vcfs_idx = ClusterVariants.out_index,
      merge_sort = true,
      outfile_prefix = "~{batch}.clustered",
      sv_base_mini_docker = sv_base_mini_docker,
      runtime_attr_override = runtime_attr_concat
  }

  call FilterDepthOnlyBySize {
    input:
      vcf = ConcatVcfs.out,
      vcf_index = ConcatVcfs.out_index,
      size = min_depth_only_size,
      basename = batch,
      gatk_docker = gatk_docker,
      runtime_attr_override = runtime_attr_filter_depth
  }





  call CopyNumberPosteriors {
    input:
      vcf = FilterDepthOnlyBySize.out,
      vcf_index = FilterDepthOnlyBySize.out_index,
      gcnv_intervals_vcfs = [MergeLargeCNVVcfs.out, MergeSmallCNVVcfs.out],
      gcnv_intervals_vcf_indexes = [MergeLargeCNVVcfs.out_index, MergeSmallCNVVcfs.out_index],
      ploidy_calls_tar = ploidy_calls_tar,
      ref_fasta_dict = ref_fasta_dict,
      batch = batch,
      gatk_docker = gatk_docker,
      runtime_attr_override = runtime_attr_posteriors
  }

  output {
    File out = CopyNumberPosteriors.out
    File out_index = CopyNumberPosteriors.out_index
  }
}

task CopyNumberPosteriors {
  input {
    File vcf
    File vcf_index
    Array[File] gcnv_intervals_vcfs
    Array[File] gcnv_intervals_vcf_indexes
    File ploidy_calls_tar
    File ref_fasta_dict
    String batch
    String gatk_path = "/gatk/gatk"
    String gatk_docker
    RuntimeAttr? runtime_attr_override
  }

  RuntimeAttr default_attr = object {
    cpu_cores: 1,
    mem_gb: 15,
    disk_gb: 10,
    boot_disk_gb: 10,
    preemptible_tries: 3,
    max_retries: 1
  }
  RuntimeAttr runtime_attr = select_first([runtime_attr_override, default_attr])

  Float mem_gb = select_first([runtime_attr.mem_gb, default_attr.mem_gb])
  Int java_mem_mb = ceil(mem_gb * 1000 * 0.8)

  output {
    File out = "~{batch}.aggregated.vcf.gz"
    File out_index = "~{batch}.aggregated.vcf.gz.tbi"
  }
  command <<<
    set -euo pipefail

    mkdir ploidy-calls
    tar xzf ~{ploidy_calls_tar} -C ploidy-calls
    ls ploidy-calls/SAMPLE_*/contig_ploidy.tsv > ploidy_files.list

    # Create arguments file
    echo "--cnv-intervals-vcf ~{sep=" --cnv-intervals-vcf " gcnv_intervals_vcfs}" > args.txt
    while read line; do
      echo "--ploidy-calls-file $line" >> args.txt
    done < ploidy_files.list

    ~{gatk_path} --java-options "-Xmx~{java_mem_mb}m" SVCopyNumberPosteriors \
      --arguments_file args.txt \
      --variant ~{vcf} \
      --output ~{batch}.aggregated.vcf.gz \
      --sequence-dictionary ~{ref_fasta_dict} \
      --genotype-depth-calls

  >>>
  runtime {
    cpu: select_first([runtime_attr.cpu_cores, default_attr.cpu_cores])
    memory: mem_gb + " GiB"
    disks: "local-disk " + select_first([runtime_attr.disk_gb, default_attr.disk_gb]) + " HDD"
    bootDiskSizeGb: select_first([runtime_attr.boot_disk_gb, default_attr.boot_disk_gb])
    docker: gatk_docker
    preemptible: select_first([runtime_attr.preemptible_tries, default_attr.preemptible_tries])
    maxRetries: select_first([runtime_attr.max_retries, default_attr.max_retries])
  }
}

task ClusterVariants {
  input {
    File vcf
    File vcf_index
    String vid_prefix
    String contig
    File sr_file
    File sr_index
    File pe_file
    File pe_index
    File sample_coverage_file
    File gatk_sv_cluster_exclude_intervals
    File exclude_intervals
    File exclude_intervals_index
    File ref_fasta_dict
    String batch
    String gatk_path = "/gatk/gatk"
    String gatk_docker
    RuntimeAttr? runtime_attr_override
  }

  parameter_meta {
    vcf: {
      localization_optional: true
    }
    sr_file: {
      localization_optional: true
    }
    pe_file: {
      localization_optional: true
    }
  }

  RuntimeAttr default_attr = object {
    cpu_cores: 1,
    mem_gb: 7.5,
    disk_gb: 100,
    boot_disk_gb: 10,
    preemptible_tries: 3,
    max_retries: 1
  }
  RuntimeAttr runtime_attr = select_first([runtime_attr_override, default_attr])

  Float mem_gb = select_first([runtime_attr.mem_gb, default_attr.mem_gb])
  Int java_mem_mb = ceil(mem_gb * 1000 * 0.8)

  output {
    File out = "~{batch}.clustered.vcf.gz"
    File out_index = "~{batch}.clustered.vcf.gz.tbi"
  }
  command <<<
    set -euo pipefail
    ~{gatk_path} --java-options "-Xmx~{java_mem_mb}m" SVCluster \
      -V ~{vcf} \
      -O ~{batch}.clustered.vcf.gz \
      -L ~{contig} \
      -XL ~{gatk_sv_cluster_exclude_intervals} \
      -XL ~{exclude_intervals} \
      --sequence-dictionary ~{ref_fasta_dict} \
      --split-reads-file ~{sr_file} \
      --discordant-pairs-file ~{pe_file} \
      --sample-coverage ~{sample_coverage_file} \
      --variant-prefix ~{vid_prefix}
  >>>
  runtime {
    cpu: select_first([runtime_attr.cpu_cores, default_attr.cpu_cores])
    memory: mem_gb + " GiB"
    disks: "local-disk " + select_first([runtime_attr.disk_gb, default_attr.disk_gb]) + " HDD"
    bootDiskSizeGb: select_first([runtime_attr.boot_disk_gb, default_attr.boot_disk_gb])
    docker: gatk_docker
    preemptible: select_first([runtime_attr.preemptible_tries, default_attr.preemptible_tries])
    maxRetries: select_first([runtime_attr.max_retries, default_attr.max_retries])
  }
}

task MergeSVCalls {
  input {
    Array[File] vcfs
    Array[File] vcf_indexes
    Array[File] cnmops_files
    Array[File] cnmops_file_indexes
    File ref_fasta_dict
    String batch
    String gatk_path = "/gatk/gatk"
    String gatk_docker
    RuntimeAttr? runtime_attr_override
  }

  RuntimeAttr default_attr = object {
    cpu_cores: 1,
    mem_gb: 7.5,
    disk_gb: 10,
    boot_disk_gb: 10,
    preemptible_tries: 3,
    max_retries: 1
  }
  RuntimeAttr runtime_attr = select_first([runtime_attr_override, default_attr])

  Float mem_gb = select_first([runtime_attr.mem_gb, default_attr.mem_gb])
  Int java_mem_mb = ceil(mem_gb * 1000 * 0.8)

  output {
    File out = "~{batch}.merged.vcf.gz"
    File out_index = "~{batch}.merged.vcf.gz.tbi"
  }
  command <<<
    set -euo pipefail

    # Create arguments file
    touch args.txt
    while read line; do
      echo "--cnmops $line" >> args.txt
    done < ~{write_lines(cnmops_files)}

    while read line; do
      echo "-V $line" >> args.txt
    done < ~{write_lines(vcfs)}

    ~{gatk_path} --java-options "-Xmx~{java_mem_mb}m" MergeSVCalls \
      --arguments_file args.txt \
      --sequence-dictionary ~{ref_fasta_dict} \
      --output ~{batch}.merged.vcf.gz \
      --ignore-dict
  >>>
  runtime {
    cpu: select_first([runtime_attr.cpu_cores, default_attr.cpu_cores])
    memory: mem_gb + " GiB"
    disks: "local-disk " + select_first([runtime_attr.disk_gb, default_attr.disk_gb]) + " HDD"
    bootDiskSizeGb: select_first([runtime_attr.boot_disk_gb, default_attr.boot_disk_gb])
    docker: gatk_docker
    preemptible: select_first([runtime_attr.preemptible_tries, default_attr.preemptible_tries])
    maxRetries: select_first([runtime_attr.max_retries, default_attr.max_retries])
  }
}

task SVTrainDepth {
  input {
    File depth_file
    File intervals
    File ploidy_calls_tar
    File sample_coverage_file
    File ref_dict
    String model_name
    String gatk_docker
    String device
    Int? max_iter
    RuntimeAttr? runtime_attr_override
  }

  parameter_meta {
    depth_file: {
           localization_optional: true
         }
  }

  RuntimeAttr default_attr = object {
                               cpu_cores: 1,
                               mem_gb: 3.75,
                               disk_gb: 15,
                               boot_disk_gb: 10,
                               preemptible_tries: 3,
                               max_retries: 1
                             }
  RuntimeAttr runtime_attr = select_first([runtime_attr_override, default_attr])

  Float mem_gb = select_first([runtime_attr.mem_gb, default_attr.mem_gb])
  Int java_mem_mb = ceil(mem_gb * 1000 * 0.8)

  output {
    File out = "~{model_name}.cnv_model.tar.gz"
  }
  command <<<
    set -euo pipefail

    mkdir ploidy-calls
    tar xzf ~{ploidy_calls_tar} -C ploidy-calls
    ls ploidy-calls/SAMPLE_*/contig_ploidy.tsv > ploidy_files.list

    # Create arguments file
    while read line; do
    echo "--ploidy-calls-file $line" >> args.txt
    done < ploidy_files.list

    mkdir svmodel
    gatk --java-options -Xmx~{java_mem_mb}M SVTrainDepth \
      -L ~{intervals} \
      --depth-file ~{depth_file} \
      --coverage-file ~{sample_coverage_file} \
      --output-name ~{model_name} \
      --output-dir svmodel \
      --arguments_file args.txt \
      --sequence-dictionary ~{ref_dict} \
      --jit \
      ~{"--max-iter " + max_iter}

    tar czf ~{model_name}.cnv_model.tar.gz svmodel/*
  >>>
  runtime {
    cpu: select_first([runtime_attr.cpu_cores, default_attr.cpu_cores])
    memory: mem_gb + " GiB"
    disks: "local-disk " + select_first([runtime_attr.disk_gb, default_attr.disk_gb]) + " HDD"
    bootDiskSizeGb: select_first([runtime_attr.boot_disk_gb, default_attr.boot_disk_gb])
    docker: gatk_docker
    preemptible: select_first([runtime_attr.preemptible_tries, default_attr.preemptible_tries])
    maxRetries: select_first([runtime_attr.max_retries, default_attr.max_retries])
  }
}

task SVInferDepth {
  input {
    File model_tar
    File ref_dict
    Int predictive_samples
    Int predictive_iter
    Int discrete_samples
    String model_name
    String output_vcf_filename
    String gatk_docker
    String device
    RuntimeAttr? runtime_attr_override
  }

  RuntimeAttr default_attr = object {
                               cpu_cores: 1,
                               mem_gb: 7.5,
                               disk_gb: 10,
                               boot_disk_gb: 15,
                               preemptible_tries: 3,
                               max_retries: 0
                             }
  RuntimeAttr runtime_attr = select_first([runtime_attr_override, default_attr])

  Float mem_gb = select_first([runtime_attr.mem_gb, default_attr.mem_gb])
  Int java_mem_mb = ceil(mem_gb * 1000 * 0.8)

  output {
    File out = "~{output_vcf_filename}"
    File out_index = "~{output_vcf_filename}.tbi"
  }
  command <<<

    set -eo pipefail
    mkdir svmodel
    tar xzf ~{model_tar} svmodel/

    gatk --java-options -Xmx~{java_mem_mb}M SVInferDepth \
      --output ~{output_vcf_filename} \
      --predictive-samples ~{predictive_samples} \
      --predictive-iter ~{predictive_iter} \
      --discrete-samples ~{discrete_samples} \
      --model-name ~{model_name} \
      --model-dir svmodel \
      --sequence-dictionary ~{ref_dict} \
      --jit

  >>>
  runtime {
    cpu: select_first([runtime_attr.cpu_cores, default_attr.cpu_cores])
    memory: mem_gb + " GiB"
    disks: "local-disk " + select_first([runtime_attr.disk_gb, default_attr.disk_gb]) + " HDD"
    bootDiskSizeGb: select_first([runtime_attr.boot_disk_gb, default_attr.boot_disk_gb])
    docker: gatk_docker
    preemptible: select_first([runtime_attr.preemptible_tries, default_attr.preemptible_tries])
    maxRetries: select_first([runtime_attr.max_retries, default_attr.max_retries])
  }
}


task MergeVcfs {
  input {
    Array[File] vcfs
    Array[File] vcf_indexes
    String output_name
    String sv_base_mini_docker
    RuntimeAttr? runtime_attr_override
  }

  RuntimeAttr default_attr = object {
    cpu_cores: 1,
    mem_gb: 3.75,
    disk_gb: 10,
    boot_disk_gb: 10,
    preemptible_tries: 3,
    max_retries: 1
  }
  RuntimeAttr runtime_attr = select_first([runtime_attr_override, default_attr])

  output {
    File out = "~{output_name}"
    File out_index = "~{output_name}.tbi"
  }
  command <<<

    set -euo pipefail
    bcftools merge --file-list ~{write_lines(vcfs)} -o ~{output_name} --output-type z
    tabix ~{output_name}

  >>>
  runtime {
    cpu: select_first([runtime_attr.cpu_cores, default_attr.cpu_cores])
    memory: select_first([runtime_attr.mem_gb, default_attr.mem_gb]) + " GiB"
    disks: "local-disk " + select_first([runtime_attr.disk_gb, default_attr.disk_gb]) + " HDD"
    bootDiskSizeGb: select_first([runtime_attr.boot_disk_gb, default_attr.boot_disk_gb])
    docker: sv_base_mini_docker
    preemptible: select_first([runtime_attr.preemptible_tries, default_attr.preemptible_tries])
    maxRetries: select_first([runtime_attr.max_retries, default_attr.max_retries])
  }
}

task SmallCNVIntervals {
  input {
    File vcf
    File vcf_index
    File ref_fasta_fai
    Int size = 5000
    Int padding = 1000
    String batch
    String sv_pipeline_docker
    RuntimeAttr? runtime_attr_override
  }

  RuntimeAttr default_attr = object {
    cpu_cores: 1,
    mem_gb: 1.0,
    disk_gb: 10,
    boot_disk_gb: 10,
    preemptible_tries: 3,
    max_retries: 1
  }
  RuntimeAttr runtime_attr = select_first([runtime_attr_override, default_attr])

  output {
    File out = "~{batch}.small_cnv_intervals.bed"
  }
  command <<<
    set -euo pipefail
    python > small_cnvs.bed <<EOF
import sys
from pysam import VariantFile
vcf = VariantFile('~{vcf}')
types = set(['DEL', 'DUP', 'BND'])
for record in vcf.fetch():
  if record.info['SVTYPE'] in types \
    and record.info['ALGORITHMS'] != 'depth' \
    and record.chrom == record.info['CHR2'] \
    and record.info['STRANDS'][0] != record.info['STRANDS'][1] \
    and record.stop - record.pos < ~{size}:
    fields = [record.chrom, str(record.pos), str(record.stop)]
    print('\t'.join(fields))
EOF

    bedtools slop -b ~{padding} -i small_cnvs.bed -g ~{ref_fasta_fai} \
      | bedtools merge \
      > ~{batch}.small_cnv_intervals.bed

  >>>
  runtime {
    cpu: select_first([runtime_attr.cpu_cores, default_attr.cpu_cores])
    memory: select_first([runtime_attr.mem_gb, default_attr.mem_gb]) + " GiB"
    disks: "local-disk " + select_first([runtime_attr.disk_gb, default_attr.disk_gb]) + " HDD"
    bootDiskSizeGb: select_first([runtime_attr.boot_disk_gb, default_attr.boot_disk_gb])
    docker: sv_pipeline_docker
    preemptible: select_first([runtime_attr.preemptible_tries, default_attr.preemptible_tries])
    maxRetries: select_first([runtime_attr.max_retries, default_attr.max_retries])
  }
}

task IntersectCountsWithIntervals {
  input {
    File counts
    File interval_list
    String output_name
    Boolean gzip = true
    String sv_base_mini_docker
    RuntimeAttr? runtime_attr_override
  }

  RuntimeAttr default_attr = object {
    cpu_cores: 1,
    mem_gb: 3.75,
    disk_gb: 10,
    boot_disk_gb: 10,
    preemptible_tries: 3,
    max_retries: 1
  }
  RuntimeAttr runtime_attr = select_first([runtime_attr_override, default_attr])

  output {
    File out = "~{output_name}.gz"
  }
  command <<<

    set -euo pipefail
    zgrep -B9999999999 -m1 -v "^@" ~{counts} > ~{output_name}
    zgrep -v "^@" ~{counts} | tail -n +2 | bedtools intersect -wa -sorted -u -a stdin -b ~{interval_list} >> ~{output_name}
    if ~{gzip}; then
      bgzip ~{output_name}
    fi

  >>>
  runtime {
    cpu: select_first([runtime_attr.cpu_cores, default_attr.cpu_cores])
    memory: select_first([runtime_attr.mem_gb, default_attr.mem_gb]) + " GiB"
    disks: "local-disk " + select_first([runtime_attr.disk_gb, default_attr.disk_gb]) + " HDD"
    bootDiskSizeGb: select_first([runtime_attr.boot_disk_gb, default_attr.boot_disk_gb])
    docker: sv_base_mini_docker
    preemptible: select_first([runtime_attr.preemptible_tries, default_attr.preemptible_tries])
    maxRetries: select_first([runtime_attr.max_retries, default_attr.max_retries])
  }
}

task ShardVcf {
  input {
    File pesr_vcf
    Int records_per_shard
    String sv_pipeline_base_docker
    RuntimeAttr? runtime_attr_override
  }

  RuntimeAttr default_attr = object {
    cpu_cores: 1,
    mem_gb: 3.75,
    disk_gb: 10,
    boot_disk_gb: 10,
    preemptible_tries: 3,
    max_retries: 1
  }
  RuntimeAttr runtime_attr = select_first([runtime_attr_override, default_attr])

  Array[String] svtypes = ["DEL", "DUP", "INV", "INS"]
  Array[String] bnd_strands = ["++", "+-", "-+", "--"]
  Array[String] bnd_strand_labels = ["plus_plus", "plus_minus", "minus_plus", "minus_minus"]

  output {
    Array[File] out = glob("*.shard_*.vcf.gz")
  }
  command <<<

    set -euo pipefail
    sgrep() { grep "$@" || test $? = 1; }
    NAME=$(basename ~{pesr_vcf} .vcf.gz)
    SVTYPES=(~{sep=" " svtypes})
    zcat ~{pesr_vcf} | grep ^# > header
    for svtype in ${SVTYPES[@]}; do
      zcat ~{pesr_vcf} | grep -v ^# | sgrep -w "<${svtype}>" > records
      NUM_RECORDS=$(cat records | wc -l)
      if [ "${NUM_RECORDS}" -gt "0" ]; then
        CHUNKS=$(python -c "from math import ceil; print(ceil($NUM_RECORDS/float(~{records_per_shard})))")
        split -a9 -d -n l/$CHUNKS records records.shard_
        i=0
        for chunk in records.shard_*; do
          padded=`printf %09d $i`
          cat header $chunk | bgzip -c > $NAME.${svtype}.shard_${padded}.vcf.gz
          i=$((i+1))
        done
        rm records records.shard_*
      else
        echo "No records of type ${svtype} found"
      fi
    done

    # Handle BNDs separately
    STRANDS=(~{sep=" " bnd_strands})
    STRAND_STR=(~{sep=" " bnd_strand_labels})
    svtype="BND"
    num_strand_types=${#STRANDS[*]}
    for (( j=0; j<=$(( $num_strand_types -1 )); j++ )); do
      strand=${STRANDS[$j]}
      strand_str=${STRAND_STR[$j]}
      zcat ~{pesr_vcf} | grep -v ^# | sgrep -w "<${svtype}>" | sgrep "STRANDS=${strand}" > records
      NUM_RECORDS=$(cat records | wc -l)
      if [ "${NUM_RECORDS}" -gt "0" ]; then
        CHUNKS=$(python -c "from math import ceil; print(ceil($NUM_RECORDS/float(~{records_per_shard})))")
        split -a9 -d -n l/$CHUNKS records records.shard_
        i=0
        for chunk in records.shard_*; do
          padded=`printf %09d $i`
          cat header $chunk | bgzip -c > $NAME.${svtype}.${strand_str}.shard_${padded}.vcf.gz
          i=$((i+1))
        done
        rm records records.shard_*
      else
        echo "No records of type ${svtype} found"
      fi
    done

  >>>
  runtime {
    cpu: select_first([runtime_attr.cpu_cores, default_attr.cpu_cores])
    memory: select_first([runtime_attr.mem_gb, default_attr.mem_gb]) + " GiB"
    disks: "local-disk " + select_first([runtime_attr.disk_gb, default_attr.disk_gb]) + " HDD"
    bootDiskSizeGb: select_first([runtime_attr.boot_disk_gb, default_attr.boot_disk_gb])
    docker: sv_pipeline_base_docker
    preemptible: select_first([runtime_attr.preemptible_tries, default_attr.preemptible_tries])
    maxRetries: select_first([runtime_attr.max_retries, default_attr.max_retries])
  }
}


task FilterDepthOnlyBySize {
  input {
    File vcf
    File vcf_index
    Int size
    String basename
    String gatk_docker
    RuntimeAttr? runtime_attr_override
  }

  RuntimeAttr default_attr = object {
    cpu_cores: 1,
    mem_gb: 3.75,
    disk_gb: 10,
    boot_disk_gb: 10,
    preemptible_tries: 3,
    max_retries: 1
  }
  RuntimeAttr runtime_attr = select_first([runtime_attr_override, default_attr])

  Float mem_gb = select_first([runtime_attr.mem_gb, default_attr.mem_gb])
  Int java_mem_mb = ceil(mem_gb * 1000 * 0.8)

  output {
    File out = "~{basename}.depth_filtered.vcf.gz"
    File out_index = "~{basename}.depth_filtered.vcf.gz.tbi"
  }
  command <<<

    set -euo pipefail
    gatk --java-options -Xmx~{java_mem_mb}M SelectVariants \
      -V ~{vcf} \
      -O ~{basename}.depth_filtered.vcf.gz \
      -select "ALGORITHMS == 'depth' && SVLEN <= ~{size}" \
      --invertSelect

  >>>
  runtime {
    cpu: select_first([runtime_attr.cpu_cores, default_attr.cpu_cores])
    memory: select_first([runtime_attr.mem_gb, default_attr.mem_gb]) + " GiB"
    disks: "local-disk " + select_first([runtime_attr.disk_gb, default_attr.disk_gb]) + " HDD"
    bootDiskSizeGb: select_first([runtime_attr.boot_disk_gb, default_attr.boot_disk_gb])
    docker: gatk_docker
    preemptible: select_first([runtime_attr.preemptible_tries, default_attr.preemptible_tries])
    maxRetries: select_first([runtime_attr.max_retries, default_attr.max_retries])
  }
}